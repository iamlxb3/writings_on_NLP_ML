## 背景

这是一个与画像（UP）组合作的项目，具体的工作就是借鉴语言模型的预训练方式，在玩家的行为序列上也进行预训练。目的是为了明确清楚行为序列与聊天文本的差异性，如果能对下游任务产生正向影响，则后续会搭建完整的pipleline接入画像标签体系，并且联合发表论文（优先落地）。

一个简单的例子 （每一行代表一个行为，这些行为对应同一个玩家）：

```
400000 [行为ID] 0 [design ID] 2020-03-10 16:32:30 [时间戳]
400001 [行为ID] 0 [design ID] 2020-03-10 16:40:20 [时间戳]
400002 [行为ID] 0 [design ID] 2020-03-10 16:40:21 [时间戳]
...
400007 [行为ID] 0 [design ID] 2020-03-10 16:40:21 [时间戳]
```

我们希望用一个模型来学习玩家的行为表示，输入类似上面例子的一系列行为序列，最终输出维度（比如说768）确定的向量作为玩家的行为表示，作为下游模型的额外特征输入。

下游的任务包括流失检测、外挂检测及预测玩家下一步会进入哪一张地图

## 数据

目前数据包含了今年3月到5月份，大小在1T以上。按行为ID、Design_ID为最小单元，平均长度在3000左右。

## 评估指标

UP组提供三个下游任务作为主要评测指标，以时间进行测试集的划分，比如3、4月份数据训练，5月份数据进行训练。5月份数据的PPL可以作为参考的评测指标。

## UP组原方案

模型方面他们选择了BERT、BERT with sparse attention、BERT with time embedding。
在词表构建方面，他们选择的最小单元是 [行为ID, design ID]，并且最大词表设定在7000，覆盖程度比较低。

## 我的方案

由于序列过长，我从两方面着手改进，一个是引入了BPE tokenizer，将ID看作是char进行多ID的合并。当设定词表大小到5万时，平均长度可以降低到400左右。
另外，调研了一些efficient transformer的方法，结合hugging face的开源实现，目前可以支持BERT、Longformer、reformer、Albert 4个模型。我同时也参考了UP组的方案，在训练BERT时加入了Time embedding，实现方式和position embedding类似；具体来说，对于非BPE的tokenzier（以ID为最小单位），给定一系列时间戳序列，我会计算后一个行为序列的时间戳和当前行为序列时间戳的差值，然后换算到100毫秒作为最小单位，如果是一个持续的行为，也可以理解为是该行为的持续时间。对于BPE的tokenzier，我会计算当前的token跨越了多少个ID，然后将这几个ID的所对应的时间差值加起来。

## 进度

- [x] 模型推断部分开发，初始化需要配置参数（比如模型路径），输入为任意batch大小的行为序列，输出是batch的行为序列embedding，支持两种tokenize方式（BPE及以ID为最小单位）, 支持选择4种模型，BERT模型支持选择是否使用time embedding。（95%）
- [ ] 训练第一阶段baseline模型，用了三月份的数据，除reformer外，其余模型最大长度设定为512，reformer设定为2048 （50%）
- [ ] 第一阶段模型下游任务测试（0%）
- [ ] 提供函数接口，可以接入到UP下游任务中进行模型的fine-tune，而非提供embedding（0%）

研究方向：

1. 如何做时间的embedding
2. 特定任务下的训练目标
3. 如何对过长的序列进行压缩
4. 是否可以进行类似“分句”的操作，把一系列紧密的动作序列分开，在每个分句的序列上分开建模



```python
class Model(nn.Module):
  def __init__(self, config):
    self.behave_embeddings = nn.Embedding(768, 768)
    self.t_gate_w = nn.Linear(768, 768)
    self.t_embeddings = sinusoidal_embedding(768)
  
  def forward(self, behave_ids, timestamps):
    behave_embedding = self.behave_embeddings(behave_ids)
    t_embedding = self.t_embeddings(timestamps)
		t_embedding_gated = torch.sigmoid(self.t_gate_w(behave_embedding)) * t_embedding
  
```



 