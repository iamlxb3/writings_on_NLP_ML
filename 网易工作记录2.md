## 工程
**NLU体系重构**

- 设计全新的NLU架构，并完成设计图及设计文档包含NluTest, NluTrain, NluMatch及NLU4个模块。
- NLU校验内容整理
- **NluMatch开发**
  - ✔ 防灌水模块开发
  - ✔ 防混淆模块开发
- ✔ NluTrain开发
  - ✔ 单进程本地版本
- NluTest开发
- NLU开发
  - 解耦NER相关代码

**语料去重校验模块**

- 合并众包模块开发
- 自动化训练模块开发

## 研究

模型蒸馏相关研究

- 验证DistillBert有效性
- 模型蒸馏简要调研

预训练语言模型研究

- 通过Roberta的方式训练语言模型

根据语法来作文本生成

- 

---

-NLU模块-

【技术说明】:

NLU模块主要用于多轮对话中的意图识别和槽提取，是小西机器人平台中的重要一环，其识别的结果将决定是调用LLP还是一些对话生成模型。

【技术分析】：

NLU分几个步骤，utterance首先会经过文本补全，再进行意图的判断和槽提取；意图判断中又会经过原文匹配、正则匹配和模型匹配这三个步骤，槽提取会经过文本匹配和正则匹配两个步骤，匹配结果的优先级都是由高到低。在推断意图时，utterance首先会经过Bert抽特征，再由下游分类器进行判断。NLU模型支持文本的在线热更新，每次请求会触发模型热更，在流程图的框架下，每一个agent包含N张图，共有N+1个模型，每次更新都会更新2个模型(一级意图模型和某张图的二级意图模型)。

【技术难点】：

1. 推断速度与模型效果的权衡
   NLU是机器人框架的上游重要节点，几乎所有的utterance都会过NLU，所以对响应时间和模型准确率都有比较高的要求。因为目前的TPS要求还没有特别高，还是以模型效果为主，后续考虑用模型蒸馏降低BERT forward pass的时间

2. 热更速度与模型效果的权衡
   热更速度也对应了模型的训练时间，传统的分类模型训练方式在语料有变化是都需要全部重新训练，不利于线上人员快速体验效果，目前考虑用"在线学习"的方法做模型训练，更新一部分，训练一部分；few-shot和zero-shot是另外的思路，让模型少训练。
3. 训练模块的动态缩扩容
4. 训练数据与推断数据分布不同
   比如BERT pretrain的数据是Wiki，但是要在游戏领域用，这个效果就会比较差；可以考虑多收集一些各领域的数据，训练多个语言模型
5. 数据质量差
   针对数据噪音，之前尝试过用bootstrapping的方式训练，效果一般；针对数据质量少，实验了GPT2做文本增强的方法，有一定效果，但是无法增强句式不同的句子，这一块会持续做实验。
6. "学错"特征
   由于数据过少，模型可能会挑好学的特征学，比如学到特征是某个词，但是当这个词前带否定，就不属于这个意图，模型就可能判断错。后续会调研这一块的解决方案，目前没有很好的想法。

【技术创新点】：

V0.3版本NLU支持三段式训练，并且保证训练时能正常推断，前二段训练是为了让用户即刻体验修改话术后的效果；第三段训练基于ensemble的方式，最大程度的保证模型的效果。

V0.4版本在此基础上将训练模块从pod中解耦，开辟了专门的训练资源，并且根据"在线学习"的思路，将1个模型分解为N个模型的构想，在保证模型效果的前提下将第三段训练的时间也大大缩短。

【依赖数据】：

1. 预训练语言模型的数据，比如要在游戏内部署，最好拿到游戏内的数据来做预训练
2. 每个任务所需要的数据

【特殊依赖的资源】：

无