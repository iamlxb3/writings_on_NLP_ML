- **obviates** the need to store the entire support set to make predictions.

- we repeated training and evaluation for 5 times with different random seed for the division.

- labeling rules formalize human’s domain knowledge in a structured way.

- SSL differ in sensitivity to the amount of labeled and unlabeled data.

- SSL has seen a great streak of success.

  > A steak of: a period of time during which something continues to happen, for example to go up or down in value or to succeed or fail

- Pseudo-labels for the unlabeled data are subject to change on the fly during training.

- These methods **bear** similarity with mixup in the sense that …

- Mixup enjoys several desirable aspect of … without suffering from their drawbacks.

- We binarize G at 0.5 to obtain discrete similarity predictions.

- Another form of straw man is the contrasting of a new idea with some impossibly bad alternative, to put the new idea in a favorable light.

  > Starw man[假想论点]: an argument, claim, or opponent that is invented in order to win or create an argument

- claims of originality are much more convincing in the context of references to existing work that appears to be similar.

- **pertinent** background literature

- But claims, statements of fact, and discussion of previous work should be substantiated by reference if not substantiated within your write-up.

- We down-weight the log-probability by a factor of 10

- We refer the reader unfamiliar with the concepts to the supplementary material.

- This increase is only **fractional**

- fail to couple feature representation learning and cluster assignments effectively

- There is a large variance in the extent of controllability across topics.

- Undertake a study of …

- Broadly, for most tasks we find relatively smooth scaling with model capacity in all three settings

- Exploit spurious features of the training data

  > Spurious instance: those with potentially wrong labels in datasets
  >
  > spurious: false and not what it appears to be, or (of reasons and judgments) based on something that has not been correctly understood and therefore false

- Performance follows a power-law (幂律) trend with the amount of compute used for training
  ![image-20201020105737858](https://tva1.sinaimg.cn/large/007S8ZIlly1gjvm58lnqbj309406hwei.jpg)

- We observed a wide spread in GPT-3 performance across these datasets suggestive of varying capacity with different answer formats.

- The exact indices can be omitted for generality.

- potentially rendering most of the expensive optimization at the small budget void.

- bring forth very notable improvements on a variety of tasks.

- To truly step forward, a principled approach, with a focus on fairness and reproducibility is needed.

- but it is difficult for readers to grasp the challenges and the landmark work in the middle.

- As a result, Neural architecture search (NAS) came into being. 

- In addition, there is some work to consider how to strike a balance between performance and efficiency

- It is not conducive to readers to capture the research clues. 

- One example is reconstructing the surface form of surrounding sentences given the encoded sentence 

- In the coding stage, the network architecture consists of alternate connections of normal cells and reduction cells.

- Stronger data augmentation and more labeled data further **diminish** the value of pre-training.

- In the case that pre-training is helpful, self-training improves upon pre-training.

- We vary the amount of labeled data in COCO and the strength of data augmentation as control factors.

- pre-training is not aware of the task of interest and can fail to adapt.

- language models whose parameter count is several orders of magnitude smaller

- In the usual experimental setups, these numbers come from cross-validation or from repeated stratified random splits onto training and testing data sets.

- This validation is repeated five times, each with a new half/half partition.

- the overly confident paired t-tests over cross validation folds are giving place to the McNemar test and 5×2 cross validation.

- They allow classifier’s excellent performance on one data set to compensate for the overall bad performance, or the opposite, a total failure on one domain can **prevail over** the fair results on most others.

  > prevai: to get control or influence

- give any provisions for normality

- While comparisons using a single data set are pestered by the biased variance estimations due to dependencies between the samples of examples

  > Pester: to annoy someone by doing or asking for something repeatedly

- Our stance is that statistical tests provide certain reassurance about the validity and non-randomness of the published results.

- Other merits of the proposed algorithm that are beyond the grasp of statistical testing should also be considered and possibly even favored over pure improvements in predictive power.

- adversarial examples finely tile space like the rational numbers among the reals 

- many large labeling tasks can be effectively designed and carried out in this method at the fraction of usual expense.

  > the fraction of: a small part of something, or a small amount

- While further … will be necessary to establish the full benefits of..

- Rex was leader of the pack and, as such (As what? As the leader of the pack.), expected obedience from the other dogs. (no problem here)

- in effect: in fact, or in practice: So in effect the government have lowered taxes for the rich and raised them for the poor.

- These lessons are particularly salient given the advent of domain specialized hardware which makes it increasingly costly to stray off the beaten path of research ideas.

  > Off the beaten path: Pursuing or following a trend, development, method, etc., that is unique or atypical.

- Recent work has **blurred the divide** between triplet-based embedding training and softmax classification. 

- With the aim of helping the **avid** researcher navigate this **flurry**, this paper characterizes a large and thoughtful selection of recent efficiency-flavored “X-former” models

- Synthesizing past research findings is one of the most important tasks in advancing a line of research. 

- All these different application scenarios show that users expect to formulate complex information needs in natural language, with no limitation to their expressiveness. 

- porting the intent model, at least partially, across platforms, domains and languages.

- This line of work is orthogonal to our approach.

- Our results also contribute to the long-running nature-nurture debate in language acquisition: whether the success of neural models implies that unbiased learners can learn natural languages with enough data, or whether human abilities to acquire language given sparse stimulus implies a strong innate human learning bias.

- Dot product is equivalent to cosine similarity when the embeddings are normalized to unit hyper-sphere.

- The availability of quality parallel data follows a sharp power law, and data becomes increasingly scarce as we expand the scope of the system to more languages.

