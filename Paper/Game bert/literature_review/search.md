Keywords:

1. Time-Aware Attention
   
   - HiTANet: Hierarchical Time-Aware Attention Networks for Risk Prediction on Electronic Health Records
2. "Time-Aware Transformer"
3. "two stage training transformer"
   
   - A Two-Stage Transformer-Based Approach for Variable-Length Abstractive Summarization
4. "unsupervised summarization"
   
   - Simple Unsupervised Summarization by Contextual Matching
5. "Transformer sequence labeling"

   - Novel transformer networks for improved sequence labeling in genomics
     ![image-20201120102328743](/Users/jiashupu/Documents/writings_on_NLP_ML/Paper/Game bert/literature_review/image-20201120102328743.png)
     Transformer-XL + QKV 1d Conv Layer
   - MUSIC TRANSFORMER: GENERATING MUSIC WITH LONG-TERM STRUCTURE
   - Pop Music Transformer: Beat-based Modeling and Generation of Expressive Pop Piano Compositions
6. "Transformer long sequence"

   1. Music Transformer: Generating Music with Long-Term Structure
   2. Multi-Scale Group Transformer for Long Sequence Modeling in Speech Separation
7. "pre training task NLP"

   1. Automatic Analysis of Flaws in Pre-Trained NLP Models
8. "pretext task "

   1. code2vec: learning distributed representations of code
9. "Multi-view representation learning"

   1. A Survey of Multi-View Representation Learning
10. "Explainable embedding"
11. "multi view language pre training"

    1. InterBERT: An Effective Multi-Modal Pretraining Approach via Vision-and-Language Interaction
12. "long sequence pre-training"
    1. LakhNES: Improving Multi-instrumental Music Generation with Cross-domain Pre-training
    2. Detecting Depression with Audio/Text Sequence Modeling of Interviews









â€‹    

